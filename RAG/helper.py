import os
from config import HF_TOKEN, DOCS_DIR, PROJECT_ROOT
from llm import chat
from prompts import prompt
from indexing import embed, get_vector_store, normalize_path

def input_filter(inputs: dict) -> dict:
    '''This function takes as input the dictionary of inputs given using the dashboard interface
    It filters input values that are useful for RAG pipeline retrieval
    returns a new dictionary containing the required input'''
    relevant_keys = [
        'origin_port',
        'destination_port',
        'ship_type',
        'dwt',
        'cargo',
        'fuel_type',
        'timeframe'
    ]
    
    new = {key: inputs[key] for key in relevant_keys if key in inputs}
    return new

def retrieve(inputs:dict):
    '''This function takes as input the requirements of a charterer
    It formats the inputs into a query to facilitate retrieval 
    Retrieval only selects documents with distance <= 0.8 for relevance
    adds a new key to the inputs dictionary, with the context as value
    returns the input dictionary'''
    
    query = (
        f"As a charterer, I need insights for a {inputs.get('ship_type', 'ship')} "
        f"of about {inputs.get('dwt', 'N/A')} DWT, carrying {inputs.get('cargo', 'unspecified cargo')} "
        f"from {inputs.get('origin_port', 'unknown origin')} to {inputs.get('destination_port', 'unknown destination')} "
        f"during {inputs.get('timeframe', 'an unspecified timeframe')}. "
        f"The ship uses {inputs.get('fuel_type', 'marine fuel')}. "
        f"Please provide information about relevant maritime laws, regulations, fuel economics, "
        f"geopolitical risks, and commodity market reports related to this trade."
    )


    vectorstore = get_vector_store()
    try:
        context = vectorstore.similarity_search_with_score(query, k=20)
        filtered = []
        for doc, score in context:
            if score <= 0.8:
                meta = doc.metadata.copy()
                if "source" in meta:
                    meta["source"] = os.path.relpath(meta["source"], DOCS_DIR)
                filtered.append({
                    "content": doc.page_content,
                    "metadata": meta,
                    "score": score
                })
        final_text = [item["content"] for item in filtered]
    except Exception as e:
        print(f"Error: Retriever failed to retrieve documents. \nReason: {e}")
        return None
    inputs['context'] = "\n".join(item["content"] for item in filtered)
    relevant_doc = [item['metadata'] for item in filtered]
    return inputs,relevant_doc

def get_inputs(res:tuple):
    '''This function takes as input the return tuple from the retrieve function
    It will only return the inputs dictionary'''
    return res[0]

def get_docs(res:tuple):
    '''This function takes as input the return tuple from the retrieve function
    It will only return the relevant_doc list'''
    return res[1]

def relevant_doc(metadata:list):
    '''This function takes as input the relevant_doc list generated by the retrieve function
    Use get_docs as inputs for this function
    It will isolate the filename from the metadata and get the file base name
    Returns a dictionary of base names as keys and the relative file path as value'''
    base_names = {}
    for meta in metadata:
        source = meta.get("source", "")
        if source:
            if source not in base_names.keys():  # only process if "source" exists
                base_names[os.path.basename(source)] = source
    
    return base_names
        
def generate(inputs:dict):
    '''This function takes as input the inputs dictionary that is returned from the retrieve function 
    ensure that the input function contains the context dictionary 
    It will format the prompt as using the inputs and invoke the llm 
    it returns a string generated by the LLM'''

    necessary_keys = ['cargo',
                      'destination_port',
                      'origin_port', 
                      'cargo',
                      'fuel_type',
                      'context']
    for key in necessary_keys:
        if key not in inputs.keys():
            raise Exception(f"Missing {key} from inputs! Check inputs again!")
    response = chat.invoke(inputs)
    return response